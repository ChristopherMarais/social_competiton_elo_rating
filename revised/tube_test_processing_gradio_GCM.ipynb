{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eea3ad7-91d7-4062-acc0-724b87bc22f1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbf1ce4-a5c4-4941-8a5b-116686a35b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T21:16:57.042057Z",
     "iopub.status.busy": "2023-05-04T21:16:57.042057Z",
     "iopub.status.idle": "2023-05-04T21:16:59.316888Z",
     "shell.execute_reply": "2023-05-04T21:16:59.316888Z",
     "shell.execute_reply.started": "2023-05-04T21:16:57.042057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import warnings\n",
    "import git\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'jupyterlab'\n",
    "\n",
    "# Import own functions\n",
    "# Getting the path of the root directory so that we can import repo specific functions\n",
    "git_repo_object = git.Repo('.', search_parent_directories=True)\n",
    "git_repo_directory = git_repo_object.working_tree_dir\n",
    "\n",
    "# Setting path so that we can import functions\n",
    "sys.path.append(os.path.join(git_repo_directory, \"src\"))\n",
    "\n",
    "from elorating import calculation, dataframe # own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25234284-1619-464b-b966-28ce5fc1fe79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T21:16:59.320427Z",
     "iopub.status.busy": "2023-05-04T21:16:59.318908Z",
     "iopub.status.idle": "2023-05-04T21:16:59.327713Z",
     "shell.execute_reply": "2023-05-04T21:16:59.326688Z",
     "shell.execute_reply.started": "2023-05-04T21:16:59.320427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full path to the excel file that will be taken as input to this notebook\n",
    "# if only a name of the file is given it will look ofr hte file in the same directory as this script/notebook\n",
    "raw_data_file_path = r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\social_competiton_elo_rating\\jupyter_notebooks\\data\\pilot_3_tube_test.xlsx\"\n",
    "\n",
    "# names of sheets to process\n",
    "# if this list is empty all the sheets will be processed\n",
    "inputted_sheet_names_list = [\n",
    "    'CAGE1', \n",
    "    'CAGE2', \n",
    "    'CAGE3', \n",
    "    'CAGE4'\n",
    "]\n",
    "\n",
    "# name of column to use in all sheets whereupon sessions are divided\n",
    "# date is the default\n",
    "session_divider_column = 'date'\n",
    "\n",
    "# define the row in which the headers are found\n",
    "# The default is 0\n",
    "# amke sure that all sheets designated for processing are in this ditionary\n",
    "header_row_dict = {\n",
    "    'CAGE1': 0, \n",
    "    'CAGE4': 0\n",
    "}\n",
    "\n",
    "# define here which individuals have different original cages than the sheets they are found in\n",
    "# the individual IDs and cage names should be the same as the format followed in the input exel file\n",
    "id_to_cage = {\n",
    "    \"4.2\":\"CAGE2\",\n",
    "    \"1.1\":\"CAGE3\"\n",
    "}\n",
    "\n",
    "# define the strains of each individual\n",
    "# individual IDs should follow the same format as what was in the input excel file\n",
    "cage_to_strain = {\n",
    "    '1.1':\"C57\",\n",
    "    '1.2':\"C57\",\n",
    "    '1.3':\"C57\",\n",
    "    '1.4':\"C57\",\n",
    "    '2.1':\"C57\",\n",
    "    '2.2':\"C57\",\n",
    "    '2.3':\"C57\",\n",
    "    '2.4':\"C57\",\n",
    "    '3.1':\"C57\",\n",
    "    '3.2':\"C57\",\n",
    "    '3.3':\"C57\",\n",
    "    '3.4':\"C57\",\n",
    "    '4.1':\"CD1\",\n",
    "    '4.2':\"CD1\",\n",
    "    '4.3':\"CD1\",\n",
    "    '4.4':\"CD1\",\n",
    "    '5.1':\"CD1\",\n",
    "    '5.2':\"CD1\",\n",
    "    '5.3':\"CD1\",\n",
    "    '5.4':\"CD1\",\n",
    "    '6.1':\"CD1\",\n",
    "    '6.2':\"CD1\",\n",
    "    '6.3':\"CD1\",\n",
    "    '6.4':\"CD1\"\n",
    "}\n",
    "\n",
    "# Define names of the files and subfolers in the output folder \n",
    "subfolder_name = \"tube_test_elo_scores_pilot_3\" # this defines the subfolder in the output folder where he results will be saved\n",
    "all_sheet_scores_name = \"elo_score_history\" # name of the csv that contains all the processed information about all the input sheets\n",
    "final_elo_score_name = \"final_elo_score\" # name of the csv file of the final ELO score of each individual\n",
    "aggregate_all_pairwise_name = \"all_pairwise_results_aggregate\" # name of the csv that aggregates all pairwise interactions that were performed\n",
    "\n",
    "# define whether plots should be printed or not\n",
    "save_plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888316fe-1994-474e-af9c-a91bbac121e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T21:16:59.328704Z",
     "iopub.status.busy": "2023-05-04T21:16:59.328704Z",
     "iopub.status.idle": "2023-05-04T21:16:59.362745Z",
     "shell.execute_reply": "2023-05-04T21:16:59.361722Z",
     "shell.execute_reply.started": "2023-05-04T21:16:59.328704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function of data\n",
    "plot_name_lst = []\n",
    "fig_lst = []\n",
    "def elo_func(file):\n",
    "    ###################################################################################################\n",
    "    # full path to the excel file that will be taken as input to this notebook\n",
    "    # if only a name of the file is given it will look ofr hte file in the same directory as this script/notebook\n",
    "    raw_data_file_path = r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\social_competiton_elo_rating\\jupyter_notebooks\\data\\pilot_3_tube_test.xlsx\"\n",
    "\n",
    "    # names of sheets to process\n",
    "    # if this list is empty all the sheets will be processed\n",
    "    inputted_sheet_names_list = [\n",
    "        'CAGE1', \n",
    "        'CAGE2', \n",
    "        'CAGE3', \n",
    "        'CAGE4'\n",
    "    ]\n",
    "\n",
    "    # name of column to use in all sheets whereupon sessions are divided\n",
    "    # date is the default\n",
    "    session_divider_column = 'date'\n",
    "\n",
    "    # define the row in which the headers are found\n",
    "    # The default is 0\n",
    "    # amke sure that all sheets designated for processing are in this ditionary\n",
    "    header_row_dict = {\n",
    "        'CAGE1': 0, \n",
    "        'CAGE4': 0\n",
    "    }\n",
    "\n",
    "    # define here which individuals have different original cages than the sheets they are found in\n",
    "    # the individual IDs and cage names should be the same as the format followed in the input exel file\n",
    "    id_to_cage = {\n",
    "        \"4.2\":\"CAGE2\",\n",
    "        \"1.1\":\"CAGE3\"\n",
    "    }\n",
    "\n",
    "    # define the strains of each individual\n",
    "    # individual IDs should follow the same format as what was in the input excel file\n",
    "    cage_to_strain = {\n",
    "        '1.1':\"C57\",\n",
    "        '1.2':\"C57\",\n",
    "        '1.3':\"C57\",\n",
    "        '1.4':\"C57\",\n",
    "        '2.1':\"C57\",\n",
    "        '2.2':\"C57\",\n",
    "        '2.3':\"C57\",\n",
    "        '2.4':\"C57\",\n",
    "        '3.1':\"C57\",\n",
    "        '3.2':\"C57\",\n",
    "        '3.3':\"C57\",\n",
    "        '3.4':\"C57\",\n",
    "        '4.1':\"CD1\",\n",
    "        '4.2':\"CD1\",\n",
    "        '4.3':\"CD1\",\n",
    "        '4.4':\"CD1\",\n",
    "        '5.1':\"CD1\",\n",
    "        '5.2':\"CD1\",\n",
    "        '5.3':\"CD1\",\n",
    "        '5.4':\"CD1\",\n",
    "        '6.1':\"CD1\",\n",
    "        '6.2':\"CD1\",\n",
    "        '6.3':\"CD1\",\n",
    "        '6.4':\"CD1\"\n",
    "    }\n",
    "\n",
    "    # Define names of the files and subfolers in the output folder \n",
    "    subfolder_name = \"tube_test_elo_scores_pilot_3\" # this defines the subfolder in the output folder where he results will be saved\n",
    "    all_sheet_scores_name = \"elo_score_history\" # name of the csv that contains all the processed information about all the input sheets\n",
    "    final_elo_score_name = \"final_elo_score\" # name of the csv file of the final ELO score of each individual\n",
    "    aggregate_all_pairwise_name = \"all_pairwise_results_aggregate\" # name of the csv that aggregates all pairwise interactions that were performed\n",
    "\n",
    "    # define whether plots should be printed or not\n",
    "    save_plots = True\n",
    "\n",
    "    ###################################################################################################\n",
    "    # make a directory to store data in\n",
    "    output_dir = os.path.join(\".\", \"output\", f\"{subfolder_name}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Getting the sheet names for the excel file\n",
    "    xls = pd.ExcelFile(file.name)\n",
    "    raw_data_sheet_names = xls.sheet_names\n",
    "    if not inputted_sheet_names_list:\n",
    "        inputted_sheet_names_list = raw_data_sheet_names\n",
    "    # SELECT sheets from raw_data_sheet_names into inputted_sheet_names_list\n",
    "    # Going through each sheet and creating a dataframe of it from excel object that is already loaded\n",
    "    sheet_df_dict = {}\n",
    "    elo_df_dict = {}\n",
    "    all_earlist_dates = []\n",
    "    all_latest_dates = []\n",
    "    for selected_sheet_name in inputted_sheet_names_list:\n",
    "\n",
    "        # drop rows with no winner or loser values\n",
    "        try:\n",
    "            sheet_df_dict[selected_sheet_name] = pd.read_excel(xls, sheet_name=selected_sheet_name, header=header_row_dict[selected_sheet_name]).dropna(subset=['winner', 'loser'])\n",
    "            sheet_df_dict[selected_sheet_name][\"cage\"] = selected_sheet_name\n",
    "        except:\n",
    "            sheet_df_dict[selected_sheet_name] = pd.read_excel(xls, sheet_name=selected_sheet_name, header=0).dropna(subset=['winner', 'loser'])\n",
    "            sheet_df_dict[selected_sheet_name][\"cage\"] = selected_sheet_name\n",
    "\n",
    "        # Getting all the floats from the strings, removing any spaces and other characters\n",
    "        try:\n",
    "            sheet_df_dict[selected_sheet_name]['winner'] = sheet_df_dict[selected_sheet_name]['winner'].astype(str).apply(lambda x: re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", x)[0] if re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", x) else x)\n",
    "            sheet_df_dict[selected_sheet_name]['loser'] = sheet_df_dict[selected_sheet_name]['loser'].astype(str).apply(lambda x: re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", x)[0] if re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", x) else x)\n",
    "        except:\n",
    "            warnings.warn(f\"No 'winner' or 'loser' column(s) detected for {selected_sheet_name} sheet.\\n\"+\n",
    "                  \"Please make sure the sheets in the excel file are in the correct format!\")\n",
    "\n",
    "        # fill the empty cells in the date (session) column with values from above if a date column is present\n",
    "        try:\n",
    "            sheet_df_dict[selected_sheet_name]['date'] = sheet_df_dict[selected_sheet_name]['date'].fillna(method='ffill')\n",
    "        except:\n",
    "            warnings.warn(f\"No 'date' column detected for {selected_sheet_name} sheet.\\n\"+\n",
    "                 \"Please make sure the sheets in the excel file are in the correct format!\")\n",
    "\n",
    "        # fill the empty cells in the runner column with values from above if a runner column is present\n",
    "        try:\n",
    "            sheet_df_dict[selected_sheet_name]['runner'] = sheet_df_dict[selected_sheet_name]['runner'].fillna(method='ffill')\n",
    "        except:\n",
    "            warnings.warn(f\"No 'runner' column detected for {selected_sheet_name} sheet.\\n\"+ \n",
    "                 \"Please make sure the sheets in the excel file are in the correct format!\")\n",
    "\n",
    "        # fill the empty cells in the ties column with values from above if a ties column is present\n",
    "        # dropping all rows without 'winner' or 'loser' column values removes ties rows\n",
    "        try:\n",
    "            sheet_df_dict[selected_sheet_name]['ties'] = sheet_df_dict[selected_sheet_name]['ties'].fillna(0).astype(bool)            \n",
    "        except:\n",
    "            warnings.warn(f\"No 'ties' column detected for {selected_sheet_name} sheet.\\n\"+ \n",
    "                 \"Please make sure the sheets in the excel file are in the correct format!\")\n",
    "\n",
    "        # Seeing which rows have a different session than the previous one\n",
    "        # This will be used to plot vertical lines for each new session       \n",
    "        sheet_df_dict[selected_sheet_name][\"session_number_difference\"] = sheet_df_dict[selected_sheet_name][session_divider_column].astype('category').cat.codes.diff()\n",
    "        sheet_df_dict[selected_sheet_name][\"session_number_difference\"] = sheet_df_dict[selected_sheet_name][\"session_number_difference\"].fillna(1)\n",
    "\n",
    "        # add the cage number of the winner and loser (default is the sheet name)\n",
    "        # map cage updates to mosue ID if mouse has a different original cage\n",
    "        sheet_df_dict[selected_sheet_name][\"winner_cage\"] = sheet_df_dict[selected_sheet_name].apply(lambda row: id_to_cage.get(row[\"winner\"], selected_sheet_name), axis=1)\n",
    "        sheet_df_dict[selected_sheet_name][\"loser_cage\"] = sheet_df_dict[selected_sheet_name].apply(lambda row: id_to_cage.get(row[\"loser\"], selected_sheet_name), axis=1)\n",
    "\n",
    "        # Calculate the ELO score\n",
    "        try:    \n",
    "            elo_dict = calculation.iterate_elo_rating_calculation_for_dataframe(dataframe=sheet_df_dict[selected_sheet_name],\n",
    "                                                                                winner_id_column='winner', \n",
    "                                                                                loser_id_column='loser',\n",
    "                                                                                additional_columns=sheet_df_dict[selected_sheet_name].columns.tolist(), \n",
    "                                                                                tie_column='ties')\n",
    "        except:\n",
    "            elo_dict = calculation.iterate_elo_rating_calculation_for_dataframe(dataframe=sheet_df_dict[selected_sheet_name],\n",
    "                                                                                winner_id_column='winner', \n",
    "                                                                                loser_id_column='loser',\n",
    "                                                                                additional_columns=sheet_df_dict[selected_sheet_name].columns.tolist(),\n",
    "                                                                                tie_column=None)\n",
    "        # convert output of function dicionary to pandas dataframe \n",
    "        elo_df_dict[selected_sheet_name] = pd.DataFrame(elo_dict).T\n",
    "\n",
    "        # add subject and agent cage IDs\n",
    "        elo_df_dict[selected_sheet_name][\"subject_cage\"] = elo_df_dict[selected_sheet_name][\"cage\"]\n",
    "        elo_df_dict[selected_sheet_name][\"agent_cage\"] = elo_df_dict[selected_sheet_name][\"cage\"]\n",
    "        elo_df_dict[selected_sheet_name][\"subject_cage\"] = elo_df_dict[selected_sheet_name].apply(lambda row: id_to_cage.get(row[\"subject_id\"], selected_sheet_name), axis=1)\n",
    "        elo_df_dict[selected_sheet_name][\"agent_cage\"] = elo_df_dict[selected_sheet_name].apply(lambda row: id_to_cage.get(row[\"agent_id\"], selected_sheet_name), axis=1)\n",
    "\n",
    "        # get earliest and latest dates\n",
    "        all_earlist_dates.append(elo_df_dict[selected_sheet_name][session_divider_column].min())\n",
    "        all_latest_dates.append(elo_df_dict[selected_sheet_name][session_divider_column].max())\n",
    "\n",
    "    # Combining all the dataframes into one\n",
    "    all_sheet_elo_score_df = pd.concat(list(elo_df_dict.values()))\n",
    "\n",
    "    # get all unique IDs\n",
    "    all_subject_ids = set(all_sheet_elo_score_df[\"subject_id\"].unique()).union(set(all_sheet_elo_score_df[\"agent_id\"].unique()))\n",
    "\n",
    "    # add strain data (default is the id)\n",
    "    if cage_to_strain:\n",
    "        all_sheet_elo_score_df[\"subject_strain\"] = all_sheet_elo_score_df[\"subject_id\"]\n",
    "        all_sheet_elo_score_df[\"agent_strain\"] = all_sheet_elo_score_df[\"agent_id\"]\n",
    "        all_sheet_elo_score_df[\"subject_strain\"] = all_sheet_elo_score_df['subject_id'].replace(cage_to_strain)\n",
    "        all_sheet_elo_score_df[\"agent_strain\"] = all_sheet_elo_score_df['agent_id'].replace(cage_to_strain)\n",
    "\n",
    "    # get final elo score for each subject\n",
    "    final_subject_elo_score_df = all_sheet_elo_score_df.drop_duplicates(subset='subject_id', keep='last')\n",
    "\n",
    "    # get rank for each elo score\n",
    "    final_subject_elo_score_df = final_subject_elo_score_df.copy()\n",
    "    final_subject_elo_score_df[\"rank\"] = final_subject_elo_score_df.groupby(\"subject_cage\")[\"updated_elo_rating\"].rank(\"dense\", ascending=False)\n",
    "    final_subject_elo_score_df = final_subject_elo_score_df[[\"subject_id\",\"subject_cage\",\"updated_elo_rating\",\"rank\"]].reset_index(drop=True)\n",
    "\n",
    "    # Turning the Dates into a easier to read format\n",
    "    # Getting the 0th part of split to remove seconds\n",
    "    try:\n",
    "        earliest_date = str(min(all_earlist_dates)).split()[0]\n",
    "        latest_date = str(max(all_latest_dates)).split()[0]\n",
    "    except:\n",
    "        earliest_date = None\n",
    "        latest_date = None\n",
    "\n",
    "    # get cages list\n",
    "    all_cages_list = inputted_sheet_names_list\n",
    "    \n",
    "    # get all the possible pairwise groups\n",
    "    grouped_df = pd.DataFrame(all_sheet_elo_score_df.groupby([\"subject_id\", \"agent_id\", 'loser', 'winner']).size()).reset_index()\n",
    "    # get the loser counts and list of loser IDs\n",
    "    df_loser = grouped_df.groupby([\"subject_id\", \"agent_id\"]).agg({0: 'min', 'loser': lambda x: x.unique()}).reset_index()\n",
    "    df_loser = df_loser.rename(columns={0: 'loser_count'})\n",
    "    # get only the top loser from loser list\n",
    "    df_loser['loser'] = df_loser['loser'].apply(lambda x: x[0])\n",
    "    # get the winner counts and list of winner IDs\n",
    "    df_winner= grouped_df.groupby([\"subject_id\", \"agent_id\"]).agg({0: 'max', 'winner': lambda x: x.unique()}).reset_index()\n",
    "    df_winner = df_winner.rename(columns={0: 'winner_count'})\n",
    "    # get only the top winner from winner list\n",
    "    df_winner['winner'] = df_winner['winner'].apply(lambda x: x[0])\n",
    "    # merge the winner and loser dataframes\n",
    "    df_winner_loser = pd.merge(df_loser, df_winner)\n",
    "    # get the total number of experiments and merge this vlaue with winner loser datframe\n",
    "    df_total = all_sheet_elo_score_df.groupby([\"subject_id\", \"agent_id\"]).size().reset_index()\n",
    "    df_total = df_total.rename(columns={0: 'total_count'})\n",
    "    df_pairwise_all = pd.merge(df_winner_loser, df_total)\n",
    "    # turn losing ount to 0 if it is the same as the total count\n",
    "    df_pairwise_all.loc[df_pairwise_all['loser_count'] == df_pairwise_all['total_count'], 'loser_count'] = 0\n",
    "    # add a draw column when losing count equals winning count\n",
    "    df_pairwise_all[\"draw\"] = False\n",
    "    df_pairwise_all.loc[df_pairwise_all['loser_count'] == df_pairwise_all['winner_count'], 'draw'] = True\n",
    "    # remove duplicates in experiments\n",
    "    df_pairwise_all = df_pairwise_all.drop_duplicates(df_pairwise_all.columns.difference(['subject_id', 'agent_id'])).reset_index(drop=True)\n",
    "    \n",
    "    # Save CSVs\n",
    "    all_sheet_elo_score_df.to_csv(f\"{all_sheet_scores_name}.csv\")\n",
    "    final_subject_elo_score_df.to_csv(f\"{final_elo_score_name}.csv\")\n",
    "    df_pairwise_all.to_csv(f\"{aggregate_all_pairwise_name}.csv\")\n",
    "    \n",
    "    \n",
    "    # change the config for exporting hte png iamge fro mthe plot at a higher resolution\n",
    "    config = {\n",
    "        'toImageButtonOptions': {\n",
    "            'format': 'png',\n",
    "            'filename': 'custom_image',\n",
    "            'height': 600,\n",
    "            'width': 800,\n",
    "            'scale': 10\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Getting the highest and lowest Elo rating for cutoffs of the Y-axis\n",
    "    max_elo_rating = all_sheet_elo_score_df[\"updated_elo_rating\"].max()\n",
    "    min_elo_rating = all_sheet_elo_score_df[\"updated_elo_rating\"].min()\n",
    "    max_match_num = all_sheet_elo_score_df[\"total_match_number\"].max()\n",
    "    min_match_num = all_sheet_elo_score_df[\"total_match_number\"].min()\n",
    "    \n",
    "    # plot_name_lst = []\n",
    "    # fig_lst = []\n",
    "    for key, value in elo_df_dict.items():\n",
    "        # Drawing vertical lines that represent when each session begins\n",
    "        # Based on when a row has a different session than the previous row\n",
    "        session_arr = value[value['session_number_difference'] == 1.0]['total_match_number'].unique()\n",
    "        vertical_lines_lst = []\n",
    "        for session_int in session_arr:\n",
    "            shape = {'type': 'line', \n",
    "                     'x0': session_int, \n",
    "                     'y0': min_elo_rating-50, \n",
    "                     'x1': session_int, \n",
    "                     'y1': max_elo_rating+50,\n",
    "                     'line': {\n",
    "                        'color': 'black',\n",
    "                        'width': 2,\n",
    "                        'dash': 'dash'\n",
    "                    }}\n",
    "            vertical_lines_lst.append(shape)\n",
    "\n",
    "        # Drawing a line for each subject\n",
    "        subject_id_arr = value['subject_id'].unique()\n",
    "        subject_id_arr.sort()\n",
    "        subject_lines_lst = []\n",
    "        for subject in subject_id_arr:\n",
    "            subject_df = value[value['subject_id'] == subject]\n",
    "            trace = go.Scatter(x=subject_df[\"total_match_number\"], \n",
    "                               y=subject_df[\"updated_elo_rating\"], \n",
    "                               mode='lines+markers', \n",
    "                               name=subject)\n",
    "            subject_lines_lst.append(trace)\n",
    "\n",
    "        # Create a layout with the shapes\n",
    "        layout = go.Layout(shapes=vertical_lines_lst)\n",
    "\n",
    "        # Create a Figure object with the traces and layout\n",
    "        fig = go.Figure(data=subject_lines_lst, layout=layout)\n",
    "        fig.update_xaxes(range=[min_match_num-2, max_match_num+2])\n",
    "        fig.update_layout(\n",
    "                         legend_title_text='Subject ID',\n",
    "                         title_text=f'ELO Score for {key}',\n",
    "                         xaxis_title='Trial Number',\n",
    "                         yaxis_title='ELO Score',\n",
    "                         # width=1000,\n",
    "                         height=600,\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "        # Show the figure\n",
    "        # fig.show(config=config)\n",
    "\n",
    "        # save figures to disk\n",
    "        # if kaleido is not installed only html is exported (a png can be saved from the html file)\n",
    "        if save_plots:\n",
    "            plot_name = f'ELO Score for {key}'+'.html'\n",
    "            fig.write_html(plot_name, config=config)\n",
    "            plot_name_lst.append(plot_name)\n",
    "            # add objects to lists\n",
    "            fig_html = pio.to_html(fig, config=config)\n",
    "            \n",
    "            fig_lst.append(fig)\n",
    "    \n",
    "    with zipfile.ZipFile('plots.zip', 'w') as myzip:\n",
    "        for i in plot_name_lst:\n",
    "            myzip.write(i)\n",
    "    \n",
    "    output_tup = (\n",
    "        all_sheet_elo_score_df.head(5).to_html(), \n",
    "        f\"{all_sheet_scores_name}.csv\",\n",
    "        final_subject_elo_score_df.head(5).to_html(),\n",
    "        f\"{final_elo_score_name}.csv\",\n",
    "        df_pairwise_all.head(5).to_html(),\n",
    "        f\"{aggregate_all_pairwise_name}.csv\",\n",
    "        fig,\n",
    "        'plots.zip'\n",
    "           )\n",
    "    all_output_tup = tuple(list(output_tup) + fig_lst)\n",
    "    return all_output_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d647e-1dc0-4871-93e9-e434a3b8f031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952bd43d-c2f7-4175-9d9f-3391d74bc717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T21:16:59.363746Z",
     "iopub.status.busy": "2023-05-04T21:16:59.363746Z",
     "iopub.status.idle": "2023-05-04T21:17:01.021868Z",
     "shell.execute_reply": "2023-05-04T21:17:01.021868Z",
     "shell.execute_reply.started": "2023-05-04T21:16:59.363746Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define gradio display\n",
    "plot_var_lst = []\n",
    "with gr.Blocks() as demo:\n",
    "    # First Block\n",
    "    # First Tab\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Input\"):\n",
    "            # inputs\n",
    "            file_input = gr.File()\n",
    "            calc_eso = gr.Button(\"Calculate ELO Scores\")            \n",
    "            \n",
    "        with gr.TabItem(\"Output\"):\n",
    "            # outputs\n",
    "            gr.Markdown(\"## **ELO Score History**\")\n",
    "            all_sheet_elo_score_display_output = gr.HTML()\n",
    "            all_sheet_elo_score_df_output = gr.File()\n",
    "\n",
    "            gr.Markdown(\"## **Final ELO Score**\")\n",
    "            final_subject_elo_score_display_output = gr.HTML()\n",
    "            final_subject_elo_score_df_output = gr.File()\n",
    "\n",
    "            gr.Markdown(\"## **All Pairwise Results Aggregate**\")\n",
    "            display_pairwise_all_output = gr.HTML()\n",
    "            df_pairwise_all_output = gr.File()\n",
    "            \n",
    "            gr.Markdown(\"## **ELO Score Plots**\")\n",
    "            plot = gr.Plot()\n",
    "            plots_dl = gr.File()\n",
    "            # for i in fig_lst:\n",
    "            #     plot_var = gr.Plot()\n",
    "            #     plot_var_lst.append(plot_var)\n",
    "            \n",
    "            \n",
    "    calc_eso.click(elo_func, \n",
    "                 file_input, \n",
    "                 [\n",
    "                    all_sheet_elo_score_display_output,\n",
    "                    all_sheet_elo_score_df_output,\n",
    "                    final_subject_elo_score_display_output,\n",
    "                    final_subject_elo_score_df_output,\n",
    "                    display_pairwise_all_output,\n",
    "                    df_pairwise_all_output,\n",
    "                    plot,\n",
    "                    plots_dl\n",
    "                 ]#+plot_var_lst\n",
    "                  )\n",
    "    \n",
    "    demo.launch()#debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f8ee54d6a5e4a8880ade41546e056b482b8e637dc064f40b470e6968242c2bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
